{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "from thop import profile\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_time_cpu(model, device, rep = 10):\n",
    "    model = model.to(device=device)\n",
    "    x = torch.rand((2, 16, 9), device=device)\n",
    "    timings=np.zeros((rep,1))\n",
    "    for i in range(rep):    \n",
    "        start_time = time.time()\n",
    "        out = model(x)\n",
    "        timings[i] = time.time() - start_time\n",
    "    mean_syn = np.sum(timings) / rep\n",
    "    std_syn = np.std(timings)\n",
    "    return mean_syn, std_syn\n",
    "\n",
    "def measure_time_gpu(model, device, rep):\n",
    "    model = model.to(device=device)\n",
    "    dummy_input = torch.randn(2, 16, 9, dtype=torch.float).to(device)\n",
    "    # INIT LOGGERS\n",
    "    starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "    repetitions = rep\n",
    "    timings=np.zeros((repetitions,1))\n",
    "    #GPU-WARM-UP\n",
    "    for _ in range(100):\n",
    "        _ = model(dummy_input)\n",
    "    # MEASURE PERFORMANCE\n",
    "    with torch.no_grad():\n",
    "        for rep in range(repetitions):\n",
    "            starter.record()\n",
    "            _ = model(dummy_input)\n",
    "            ender.record()\n",
    "            # WAIT FOR GPU SYNC\n",
    "            torch.cuda.synchronize()\n",
    "            curr_time = starter.elapsed_time(ender)\n",
    "            timings[rep] = curr_time\n",
    "    mean_syn = np.sum(timings) / repetitions\n",
    "    std_syn = np.std(timings)\n",
    "    return mean_syn, std_syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init Conv1dTransformerEncoder with 7 classes\n"
     ]
    }
   ],
   "source": [
    "from model.model import Conv1dAnomalyTransformer, OnlyAnomalyTransformer\n",
    "\n",
    "model = Conv1dAnomalyTransformer(\n",
    "    d_model=10,\n",
    "    layer=10,\n",
    "    num_class=7,\n",
    "    with_time=False,\n",
    "    use_emb=True,\n",
    "    add_norm=True,\n",
    "    in_dim=9,\n",
    "    emb_size=64,\n",
    "    win_size=16\n",
    ").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19.954039329528808, 1.7465905460901445)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_time_gpu(model, 'cuda', rep=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter count: 160356\n",
      "Model weights: 160356\n",
      "MAC: 25714046736\n"
     ]
    }
   ],
   "source": [
    "def calculate_MAC(parameter_count, model_weights):\n",
    "    mac = parameter_count * model_weights\n",
    "    return mac\n",
    "\n",
    "def calculate_parameter_count(model):\n",
    "    parameter_count = sum(p.numel() for p in model.parameters())\n",
    "    return parameter_count\n",
    "\n",
    "def calculate_model_weights(model):\n",
    "    model_weights = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return model_weights\n",
    "\n",
    "parameter_count = calculate_parameter_count(model)\n",
    "model_weights = calculate_model_weights(model)\n",
    "mac = calculate_MAC(parameter_count, model_weights)\n",
    "\n",
    "print(f\"Parameter count: {parameter_count}\")\n",
    "print(f\"Model weights: {model_weights}\")\n",
    "print(f\"MAC: {mac}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv1d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm1d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "MACs: 2,035,648.0, Parameters: 160.156 using THOP\n",
      "MACs: 3977216 using torchprofile\n"
     ]
    }
   ],
   "source": [
    "from torchprofile import profile_macs\n",
    "from thop import profile\n",
    "\n",
    "macs, params = profile(model, inputs=(input_tensor,))\n",
    "print(f\"MACs: {f'{macs:,}' }, Parameters: {f'{params:,}' } using THOP\")\n",
    "\n",
    "inputs = torch.randn(2, 16, 9).to('cuda')\n",
    "macs = profile_macs(model.to(inputs.device), inputs)\n",
    "print(f\"MACs: {macs} using torchprofile\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
